{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "input_path=\"./data/ranked/\"\n",
    "output_path=\"./data/summaries_kmeans/\"\n",
    "if os.path.exists(output_path) == False:\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "def clean_text(row):\n",
    "    text = []\n",
    "    [text.extend(i.strip().split('ред')) for i in row]\n",
    "    text = [i.strip() for i in text]\n",
    "    text = list(filter(None, text))\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def get_sentences():\n",
    "    train = pd.read_csv(f'{input_path}train.csv')\n",
    "    test = pd.read_csv(f'{input_path}test.csv')\n",
    "    val = pd.read_csv(f'{input_path}val.csv')\n",
    "    #Comment\n",
    "    train = train.head(1)\n",
    "    test = test.head(1)\n",
    "    val = val.head(1)\n",
    "    #Comment\n",
    "\n",
    "    train['segments'] = train['segments'].apply(eval)\n",
    "    test['segments'] = test['segments'].apply(eval)\n",
    "    val['segments'] = val['segments'].apply(eval)\n",
    "\n",
    "    train_sentences = train['segments'].apply(lambda x: clean_text(x['facts-and-arguments']))\n",
    "    test_sentences = test['segments'].apply(lambda x: clean_text(x['facts-and-arguments']))\n",
    "    val_sentences = val['segments'].apply(lambda x: clean_text(x['facts-and-arguments']))\n",
    "\n",
    "    return train,test,val,train_sentences, val_sentences, test_sentences\n",
    "\n",
    "train,test,val,train_sentences, val_sentences, test_sentences = get_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def summarize(sentences):\n",
    "    embeddings = model.encode(sentences)\n",
    "    k=len(sentences)//4\n",
    "    kmeans = KMeans(n_clusters=k, n_init=k,random_state=0).fit(embeddings)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    cluster_indices = kmeans.predict(embeddings)\n",
    "\n",
    "    summary_sentences = []\n",
    "    for i in range(k):\n",
    "        cluster = [sentences[j] for j in range(len(sentences)) if cluster_indices[j] == i]\n",
    "        cluster_embeddings = [embeddings[j] for j in range(len(sentences)) if cluster_indices[j] == i]\n",
    "        centroid = cluster_centers[i]\n",
    "        closest_sentence_idx = min(range(len(cluster_embeddings)), key=lambda x: cosine_similarity([centroid], [cluster_embeddings[x]]))\n",
    "        summary_sentences.append(cluster[closest_sentence_idx])\n",
    "    return summary_sentences\n",
    "\n",
    "train_summary = []\n",
    "val_summary = []\n",
    "test_summary = []\n",
    "\n",
    "\n",
    "for i in range(len(train_sentences)):\n",
    "    train_summary.append(summarize(train_sentences[i]))\n",
    "\n",
    "for i in range(len(val_sentences)):\n",
    "    val_summary.append(summarize(val_sentences[i]))\n",
    "\n",
    "for i in range(len(test_sentences)):\n",
    "    test_summary.append(summarize(test_sentences[i]))\n",
    "\n",
    "train['summary'] = train_summary\n",
    "val['summary'] = val_summary\n",
    "test['summary'] = test_summary\n",
    "train.to_csv(f'{output_path}train.csv', index=False)\n",
    "val.to_csv(f'{output_path}val.csv', index=False)\n",
    "test.to_csv(f'{output_path}test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLDC",
   "language": "python",
   "name": "hldc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
